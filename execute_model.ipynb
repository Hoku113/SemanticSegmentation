{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and start prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as albu\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helper():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def visualize(**images):\n",
    "        \"\"\"Plot images in one row\"\"\"\n",
    "        n = len(images)\n",
    "        plt.figure(figsize=(16, 5))\n",
    "        for i, (name, image) in enumerate(images.items()):\n",
    "            plt.subplot(1, n, i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.title(\"\".join(name.split('_')).title())\n",
    "            plt.imshow(image)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_training_augmentation(self):\n",
    "        IMAGE_SIZE = 256\n",
    "        train_transform = [\n",
    "            albu.HorizontalFlip(p=0.5),\n",
    "            albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, border_mode=0),\n",
    "            albu.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, always_apply=True, border_mode=0),\n",
    "            albu.RandomCrop(height=IMAGE_SIZE, width=IMAGE_SIZE, always_apply=True),\n",
    "            albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "            albu.IAAPerspective(p=0.5),\n",
    "\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.CLAHE(p=1),\n",
    "                    albu.RandomBrightness(p=1),\n",
    "                    albu.RandomGamma(p=1),\n",
    "                ],\n",
    "                p=0.9,\n",
    "            ),\n",
    "\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.IAASharpen(p=1),\n",
    "                    albu.Blur(blur_limit=3, p=1),\n",
    "                    albu.MotionBlur(blur_limit=3, p=1)\n",
    "                ],\n",
    "                p=0.9,\n",
    "            ),\n",
    "\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.RandomContrast(p=1),\n",
    "                    albu.HueSaturationValue(p=1)\n",
    "                ],\n",
    "                p=0.9,\n",
    "            ),\n",
    "        ]\n",
    "        return albu.Compose(train_transform)\n",
    "\n",
    "    def to_tensor(self, x, **kwargs):\n",
    "        return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "    def get_preprocessing(self, preprocessing_fn):\n",
    "        self._transform = [\n",
    "            albu.Lambda(image=preprocessing_fn),\n",
    "            albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "        ]\n",
    "        return albu.Compose(self._transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    CLASSES=['background', 'dog']\n",
    "    def __init__(self, images_dir, masks_dir, classes=None, augmentation=None, preprocessing=None):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [classes.index(cls.lower()) for cls in classes]\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getItem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # mask\n",
    "        mask = cv2.imread(self.masks_fps[i])\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37cba68cc0666ff0500346fbbc272670c42c6c1b2383619b4dcb2ba70df940d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
